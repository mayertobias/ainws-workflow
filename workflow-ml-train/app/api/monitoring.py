"""
Monitoring API for real-time pipeline progress tracking.

Provides endpoints for:
- Real-time pipeline status
- Progress monitoring
- Logs and metrics
- Performance tracking
"""

from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect, Request
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
import logging
import json
from datetime import datetime, timedelta
import asyncio

logger = logging.getLogger(__name__)

router = APIRouter()

# =============================================================================
# RESPONSE MODELS
# =============================================================================

class PipelineStatusResponse(BaseModel):
    """Detailed pipeline status response"""
    pipeline_id: str
    status: str  # starting, running, completed, failed, stopped
    strategy: str
    experiment_name: str
    current_stage: Optional[str] = None
    progress: Dict[str, Any] = Field(default_factory=dict)
    timing: Dict[str, Any] = Field(default_factory=dict)
    logs: List[str] = Field(default_factory=list)
    metrics: Dict[str, Any] = Field(default_factory=dict)

class SystemHealthResponse(BaseModel):
    """System health response"""
    status: str
    timestamp: datetime
    services: Dict[str, str]
    resources: Dict[str, Any]
    active_pipelines: int

# =============================================================================
# PIPELINE MONITORING
# =============================================================================

@router.get("/status/{pipeline_id}", response_model=PipelineStatusResponse)
async def get_pipeline_status(pipeline_id: str, request: Request):
    """
    Get comprehensive pipeline status with real-time progress.
    
    Returns detailed information about pipeline execution including:
    - Current stage and progress
    - Timing information
    - Recent logs
    - Performance metrics
    """
    try:
        # Get orchestrator from app state using request
        if hasattr(request.app.state, 'orchestrator') and request.app.state.orchestrator:
            orchestrator = request.app.state.orchestrator
            
            logger.info(f"üîç Looking for pipeline {pipeline_id} in orchestrator")
            
            # Get real pipeline status
            pipeline_status = orchestrator.get_pipeline_status(pipeline_id)
            
            if not pipeline_status:
                # Also check if it's in active pipelines
                active_pipelines = orchestrator.list_active_pipelines()
                logger.warning(f"‚ùå Pipeline {pipeline_id} not found. Active pipelines: {[p.get('pipeline_id') for p in active_pipelines]}")
                raise HTTPException(status_code=404, detail=f"Pipeline {pipeline_id} not found")
            
            logger.info(f"‚úÖ Found pipeline {pipeline_id}: status={pipeline_status.get('status')}, stage={pipeline_status.get('current_stage')}")
            
            # Convert orchestrator status to API response format
            status = pipeline_status.get('status', 'unknown')
            strategy = pipeline_status.get('strategy', 'unknown')
            experiment_name = pipeline_status.get('experiment_name', 'unknown')
            current_stage = pipeline_status.get('current_stage', None)
            
            # Calculate progress from stages
            stages_info = pipeline_status.get('stages', {})
            stage_progress = {}
            completed_stages = 0
            total_stages = len(stages_info)
            
            for stage_name, stage_data in stages_info.items():
                stage_status = stage_data.get('status', 'pending')
                if stage_status == 'completed':
                    stage_progress[stage_name] = {"status": "completed", "progress": 100}
                    completed_stages += 1
                elif stage_status == 'running':
                    stage_progress[stage_name] = {"status": "running", "progress": 50}  # Assume 50% for running
                elif stage_status == 'failed':
                    stage_progress[stage_name] = {"status": "failed", "progress": 0}
                else:
                    stage_progress[stage_name] = {"status": "pending", "progress": 0}
            
            # Calculate overall progress
            overall_progress = (completed_stages / total_stages * 100) if total_stages > 0 else 0
            if current_stage and stages_info.get(current_stage, {}).get('status') == 'running':
                overall_progress += (50 / total_stages)  # Add partial progress for current stage
            
            # Get timing information
            start_time = pipeline_status.get('start_time')
            end_time = pipeline_status.get('end_time')
            
            timing = {}
            if start_time:
                timing['start_time'] = start_time.isoformat() if hasattr(start_time, 'isoformat') else str(start_time)
                
                if end_time:
                    timing['end_time'] = end_time.isoformat() if hasattr(end_time, 'isoformat') else str(end_time)
                    elapsed = (end_time - start_time).total_seconds() if hasattr(start_time, 'total_seconds') else 0
                else:
                    from datetime import datetime
                    elapsed = (datetime.now() - start_time).total_seconds() if hasattr(start_time, 'total_seconds') else 0
                
                timing['elapsed_seconds'] = int(elapsed)
                
                # Estimate total time based on progress
                if overall_progress > 0 and status in ['running', 'starting']:
                    estimated_total = elapsed * (100 / overall_progress)
                    timing['estimated_total_seconds'] = int(estimated_total)
                    
                    remaining = estimated_total - elapsed
                    if remaining > 0:
                        from datetime import datetime, timedelta
                        eta = datetime.now() + timedelta(seconds=remaining)
                        timing['eta'] = eta.isoformat()
            
            # Generate logs
            logs = [
                f"{timing.get('start_time', 'unknown')} - Pipeline {pipeline_id} started with strategy '{strategy}'",
            ]
            
            for stage_name, stage_data in stages_info.items():
                stage_status = stage_data.get('status', 'pending')
                if stage_status != 'pending':
                    logs.append(f"{timing.get('start_time', 'unknown')} - Stage '{stage_name}': {stage_status}")
            
            if 'error_message' in pipeline_status:
                logs.append(f"{timing.get('start_time', 'unknown')} - ERROR: {pipeline_status['error_message']}")
            
            # Get metrics from training results if available
            metrics = {}
            if 'training_results' in pipeline_status:
                training_results = pipeline_status['training_results']
                metrics.update({
                    'accuracy': training_results.get('accuracy', 0),
                    'n_features': training_results.get('n_features', 0),
                    'model_type': training_results.get('model_type', 'unknown'),
                    'mlflow_run_id': training_results.get('mlflow_run_id', 'unknown')
                })
            
            # Add general metrics
            if 'features' in pipeline_status:
                metrics['selected_features'] = len(pipeline_status['features'])
            
            return PipelineStatusResponse(
                pipeline_id=pipeline_id,
                status=status,
                strategy=strategy,
                experiment_name=experiment_name,
                current_stage=current_stage,
                progress={
                    "overall_percent": round(overall_progress, 1),
                    "stages": stage_progress,
                    "current_stage_detail": {
                        "name": current_stage or "unknown",
                        "description": f"Executing {current_stage.replace('_', ' ') if current_stage else 'unknown stage'}",
                        "eta_minutes": timing.get('estimated_total_seconds', 0) // 60
                    }
                },
                timing=timing,
                logs=logs[-10:],  # Last 10 logs
                metrics=metrics
            )
        else:
            # Fallback to mock data if orchestrator not available
            logger.error("‚ùå Orchestrator not available in app state")
            raise HTTPException(status_code=503, detail="ML training service not available")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to get pipeline status: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Failed to get status: {str(e)}")

@router.get("/active")
async def list_active_pipelines(request: Request):
    """List all currently active pipelines"""
    try:
        # Get orchestrator from app state using request
        if hasattr(request.app.state, 'orchestrator') and request.app.state.orchestrator:
            orchestrator = request.app.state.orchestrator
            
            # Get real active pipelines
            active_pipelines = orchestrator.list_active_pipelines()
            
            logger.info(f"üìä Found {len(active_pipelines)} active pipelines")
            
            # Convert to API format
            formatted_pipelines = []
            for pipeline in active_pipelines:
                pipeline_id = pipeline.get('pipeline_id', 'unknown')
                strategy = pipeline.get('strategy', 'unknown')
                status = pipeline.get('status', 'unknown')
                current_stage = pipeline.get('current_stage', 'unknown')
                start_time = pipeline.get('start_time')
                
                # Calculate progress
                stages_info = pipeline.get('stages', {})
                total_stages = len(stages_info)
                completed_stages = sum(1 for stage_data in stages_info.values() 
                                     if stage_data.get('status') == 'completed')
                progress_percent = (completed_stages / total_stages * 100) if total_stages > 0 else 0
                
                # Estimate ETA
                eta_minutes = 0
                if start_time and status in ['running', 'starting'] and progress_percent > 0:
                    from datetime import datetime
                    elapsed = (datetime.now() - start_time).total_seconds() / 60
                    estimated_total = elapsed * (100 / progress_percent)
                    eta_minutes = max(0, int(estimated_total - elapsed))
                
                formatted_pipelines.append({
                    "pipeline_id": pipeline_id,
                    "strategy": strategy,
                    "status": status,
                    "current_stage": current_stage,
                    "progress_percent": round(progress_percent, 1),
                    "start_time": start_time.isoformat() if hasattr(start_time, 'isoformat') else str(start_time),
                    "eta_minutes": eta_minutes
                })
            
            return {
                "active_pipelines": formatted_pipelines,
                "total_active": len(formatted_pipelines)
            }
        else:
            logger.error("‚ùå Orchestrator not available in app state")
            return {
                "active_pipelines": [],
                "total_active": 0,
                "error": "ML training service not available"
            }
        
    except Exception as e:
        logger.error(f"‚ùå Failed to list active pipelines: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list pipelines: {str(e)}")

@router.get("/logs/{pipeline_id}")
async def get_pipeline_logs(
    pipeline_id: str,
    limit: int = 50,
    level: Optional[str] = None
):
    """Get detailed logs for a specific pipeline"""
    try:
        # TODO: Get actual logs from logging system
        logs = [
            {
                "timestamp": datetime.now().isoformat(),
                "level": "INFO",
                "stage": "service_discovery",
                "message": "Discovered audio service with 25 features"
            },
            {
                "timestamp": datetime.now().isoformat(),
                "level": "INFO", 
                "stage": "service_discovery",
                "message": "Discovered content service with 12 features"
            },
            {
                "timestamp": datetime.now().isoformat(),
                "level": "INFO",
                "stage": "feature_agreement",
                "message": "Feature agreement created with 15 selected features"
            },
            {
                "timestamp": datetime.now().isoformat(),
                "level": "INFO",
                "stage": "feature_extraction",
                "message": "Started feature extraction for 100 songs"
            },
            {
                "timestamp": datetime.now().isoformat(),
                "level": "DEBUG",
                "stage": "feature_extraction",
                "message": "Extracted features for song: Billie Jean"
            }
        ]
        
        # Filter by level if specified
        if level:
            logs = [log for log in logs if log["level"] == level.upper()]
        
        return {
            "pipeline_id": pipeline_id,
            "logs": logs[:limit],
            "total_logs": len(logs),
            "available_levels": ["DEBUG", "INFO", "WARNING", "ERROR"]
        }
        
    except Exception as e:
        logger.error(f"‚ùå Failed to get pipeline logs: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get logs: {str(e)}")

# =============================================================================
# SYSTEM HEALTH
# =============================================================================

@router.get("/health", response_model=SystemHealthResponse)
async def get_system_health():
    """Get overall system health and status"""
    try:
        # TODO: Check actual system health
        return SystemHealthResponse(
            status="healthy",
            timestamp=datetime.now(),
            services={
                "audio_service": "healthy",
                "content_service": "healthy",
                "mlflow": "healthy",
                "airflow": "healthy"
            },
            resources={
                "cpu_usage": "35%",
                "memory_usage": "2.1 GB",
                "disk_usage": "15%",
                "available_memory": "6.2 GB"
            },
            active_pipelines=2
        )
        
    except Exception as e:
        logger.error(f"‚ùå Failed to get system health: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get health: {str(e)}")

@router.get("/metrics")
async def get_system_metrics(request: Request):
    """
    Get system metrics for model validation and performance tracking
    
    Returns metrics in the exact format expected by ModelValidationDashboard.tsx
    and other frontend components. This endpoint is used for:
    - Real-time validation analysis
    - Cross-validation workflow progress tracking
    - System performance monitoring
    """
    try:
        # Get orchestrator for real pipeline data if available
        orchestrator = None
        if hasattr(request.app.state, 'orchestrator') and request.app.state.orchestrator:
            orchestrator = request.app.state.orchestrator
        
        # Calculate real metrics from orchestrator or use defaults
        if orchestrator:
            try:
                # Get real pipeline statistics
                active_pipelines = orchestrator.list_active_pipelines()
                
                # Calculate metrics from actual pipeline data
                total_completed = 0
                total_failed = 0
                total_duration = 0
                duration_count = 0
                
                # This would ideally come from a persistent pipeline history store
                # For now, use the orchestrator's current state plus some reasonable defaults
                total_pipelines = len(active_pipelines) + 20  # Active + historical
                failed_pipelines = 2  # This should come from actual failure tracking
                success_rate = ((total_pipelines - failed_pipelines) / total_pipelines) if total_pipelines > 0 else 0.95
                
                # Average training duration in seconds (convert from default minutes)
                average_training_duration = 380.0  # ~6.3 minutes in seconds, matches pipeline estimates
                
                # Cache hit rate - this should come from actual cache statistics
                cache_hit_rate = 0.755  # 75.5% as decimal
                
                # Feature extraction success rate - very high for healthy system
                feature_extraction_success_rate = 0.985  # 98.5% success rate
                
            except Exception as orchestrator_error:
                logger.warning(f"Failed to get real metrics from orchestrator: {orchestrator_error}")
                # Fall back to default values
                total_pipelines = 23
                failed_pipelines = 2
                success_rate = 0.913  # 91.3%
                average_training_duration = 380.0
                cache_hit_rate = 0.755
                feature_extraction_success_rate = 0.985
        else:
            # Default values when orchestrator not available
            total_pipelines = 23
            failed_pipelines = 2
            success_rate = 0.913  # 91.3%
            average_training_duration = 380.0  # seconds
            cache_hit_rate = 0.755  # 75.5%
            feature_extraction_success_rate = 0.985  # 98.5%
        
        # Return in exact format expected by frontend (SystemMetrics interface)
        return {
            "success_rate": success_rate,
            "total_pipelines": total_pipelines,
            "failed_pipelines": failed_pipelines,
            "average_training_duration": average_training_duration,
            "cache_hit_rate": cache_hit_rate,
            "feature_extraction_success_rate": feature_extraction_success_rate
        }
        
    except Exception as e:
        logger.error(f"‚ùå Failed to get system metrics: {e}")
        # Return safe defaults to prevent frontend breakage
        return {
            "success_rate": 0.913,
            "total_pipelines": 23,
            "failed_pipelines": 2,
            "average_training_duration": 380.0,
            "cache_hit_rate": 0.755,
            "feature_extraction_success_rate": 0.985
        }

# =============================================================================
# WEBSOCKET FOR REAL-TIME UPDATES
# =============================================================================

class ConnectionManager:
    """Manage WebSocket connections for real-time updates"""
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
    
    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_text(json.dumps(message))
            except Exception as e:
                logger.error(f"Failed to send message to WebSocket: {e}")

manager = ConnectionManager()

@router.websocket("/ws/{pipeline_id}")
async def websocket_endpoint(websocket: WebSocket, pipeline_id: str):
    """
    WebSocket endpoint for real-time pipeline updates.
    
    Provides live updates for:
    - Progress changes
    - Stage transitions
    - Log messages
    - Metrics updates
    """
    await manager.connect(websocket)
    
    try:
        # Send initial status
        await websocket.send_text(json.dumps({
            "type": "status",
            "pipeline_id": pipeline_id,
            "message": "Connected to real-time updates"
        }))
        
        # Simulate real-time updates
        while True:
            # Send progress update every 5 seconds
            update = {
                "type": "progress_update",
                "pipeline_id": pipeline_id,
                "timestamp": datetime.now().isoformat(),
                "progress_percent": 75.0,
                "current_stage": "model_training",
                "message": "Training random forest model..."
            }
            
            await websocket.send_text(json.dumps(update))
            await asyncio.sleep(5)
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        logger.info(f"WebSocket disconnected for pipeline {pipeline_id}")
    except Exception as e:
        logger.error(f"WebSocket error for pipeline {pipeline_id}: {e}")
        manager.disconnect(websocket) 